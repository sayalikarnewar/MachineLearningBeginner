# Machine Learning Beginner Course 
This is a most basic way to learn how to implement Machine Learning models and get a hands-on experience and little satisfaction that we are doing something.

###### FUN FACT:
#### Why polynomial linear regression is called as linear regression?
- polynomial linear regression is actually a special case of the multiple linear regression.
- Even though it gives a polynomial equation (y = b0 + b1*x +b2*x^2 +...+bn*x^n) and so a parabolic plot of the prediction graph, when we're talking about linear and nonlinear we're not actually talking about the X variables, but the coefficients of the x - variables i.e. {b0, b1, b2...bn}
 
#### In decision tree, do we need to do feature scaling?
- no, we don't need to do feature scaling.
- and hence, there is no need of transform method, but just fit.
#### Can we use decision tree on one feature dataset?
- yes, we can. 
- decision tree regression gives the range of prediction where the features are same.
- when we plot the 2-D visualisation graph, it will give a stair-like curve.
- for more than one feature, we can't visualise the graph, as it wll be in higher dimension.
#### What is ensemble learning simply?
- Ensemble learning is when you take multiple algorithms or the same algorithm multiple times and you put them together to make something much more powerful than the original.
#### Random Forest Regression
- we have more splits as compared to decision tree(1 split), so while visualing it, we see more no of stairs.
